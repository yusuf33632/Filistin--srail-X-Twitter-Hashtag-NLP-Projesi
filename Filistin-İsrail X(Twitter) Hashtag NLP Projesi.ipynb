{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b31eb3",
   "metadata": {},
   "source": [
    "# Temel kütüphaneleri yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a714f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a121f",
   "metadata": {},
   "source": [
    "# csv dosyasındaki verileri okuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b1c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/yusuf/Desktop/pse_isr_reddit_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d01fc",
   "metadata": {},
   "source": [
    "# Veri araştırma ve temizleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9332eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>Israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>The only people starving them is Hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>The casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'You thinking what I'm thinking?\"\\n\\n\"Aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  Israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  The only people starving them is Hamas who kee...   \n",
       "2    k9tjpdl      1  The casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'You thinking what I'm thinking?\"\\n\\n\"Aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7a8e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b5f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881597e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>Israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>The only people starving them is Hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>The casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'You thinking what I'm thinking?\"\\n\\n\"Aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  Israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  The only people starving them is Hamas who kee...   \n",
       "2    k9tjpdl      1  The casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'You thinking what I'm thinking?\"\\n\\n\"Aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adac423",
   "metadata": {},
   "source": [
    "# Lower Casing(Küçük harfe çevirme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0683f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.self_text = df.self_text.str.lower()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633d729",
   "metadata": {},
   "source": [
    "# Silme işlemleri "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46e177",
   "metadata": {},
   "source": [
    "# URL silme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebd6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.str.replace(r'https?://\\S+|www\\.\\S+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e16c077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27656bfd",
   "metadata": {},
   "source": [
    "# E-posta silme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7f4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.str.replace(r'\\S+@\\S+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d4a0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b92c04a",
   "metadata": {},
   "source": [
    "# Tarih silme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9e090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.str.replace(r'\\d{1,2}(st|nd|rd|th)?[-./]\\d{1,2}[-./]\\d{2,4}', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383edad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0bfc9",
   "metadata": {},
   "source": [
    "# HTML kodları silme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e53132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.str.replace(r'<.*?>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f91d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331fe63",
   "metadata": {},
   "source": [
    "# Emoji silme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bdc2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(self_text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', self_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d29ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25ada084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['self_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1573c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04fe59f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60027018",
   "metadata": {},
   "source": [
    "# Karakter kullanarak yapılan emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee9c4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTICONS = {\n",
    "    u\":‑\\)\":\"Happy face or smiley\",\n",
    "    u\":\\)\":\"Happy face or smiley\",\n",
    "    u\":-\\]\":\"Happy face or smiley\",\n",
    "    u\":\\]\":\"Happy face or smiley\",\n",
    "    u\":-3\":\"Happy face smiley\",\n",
    "    u\":3\":\"Happy face smiley\",\n",
    "    u\":->\":\"Happy face smiley\",\n",
    "    u\":>\":\"Happy face smiley\",\n",
    "    u\"8-\\)\":\"Happy face smiley\",\n",
    "    u\":o\\)\":\"Happy face smiley\",\n",
    "    u\":-\\}\":\"Happy face smiley\",\n",
    "    u\":\\}\":\"Happy face smiley\",\n",
    "    u\":-\\)\":\"Happy face smiley\",\n",
    "    u\":c\\)\":\"Happy face smiley\",\n",
    "    u\":\\^\\)\":\"Happy face smiley\",\n",
    "    u\"=\\]\":\"Happy face smiley\",\n",
    "    u\"=\\)\":\"Happy face smiley\",\n",
    "    u\":‑D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8‑D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"X‑D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":-\\)\\)\":\"Very happy\",\n",
    "    u\":‑\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‑c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‑<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‑\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\{\":\"Frown, sad, andry or pouting\",\n",
    "    u\":@\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":'‑\\(\":\"Crying\",\n",
    "    u\":'\\(\":\"Crying\",\n",
    "    u\":'‑\\)\":\"Tears of happiness\",\n",
    "    u\":'\\)\":\"Tears of happiness\",\n",
    "    u\"D‑':\":\"Horror\",\n",
    "    u\"D:<\":\"Disgust\",\n",
    "    u\"D:\":\"Sadness\",\n",
    "    u\"D8\":\"Great dismay\",\n",
    "    u\"D;\":\"Great dismay\",\n",
    "    u\"D=\":\"Great dismay\",\n",
    "    u\"DX\":\"Great dismay\",\n",
    "    u\":‑O\":\"Surprise\",\n",
    "    u\":O\":\"Surprise\",\n",
    "    u\":‑o\":\"Surprise\",\n",
    "    u\":o\":\"Surprise\",\n",
    "    u\":-0\":\"Shock\",\n",
    "    u\"8‑0\":\"Yawn\",\n",
    "    u\">:O\":\"Yawn\",\n",
    "    u\":-\\*\":\"Kiss\",\n",
    "    u\":\\*\":\"Kiss\",\n",
    "    u\":X\":\"Kiss\",\n",
    "    u\";‑\\)\":\"Wink or smirk\",\n",
    "    u\";\\)\":\"Wink or smirk\",\n",
    "    u\"\\*-\\)\":\"Wink or smirk\",\n",
    "    u\"\\*\\)\":\"Wink or smirk\",\n",
    "    u\";‑\\]\":\"Wink or smirk\",\n",
    "    u\";\\]\":\"Wink or smirk\",\n",
    "    u\";\\^\\)\":\"Wink or smirk\",\n",
    "    u\":‑,\":\"Wink or smirk\",\n",
    "    u\";D\":\"Wink or smirk\",\n",
    "    u\":‑P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"X‑P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‑Þ\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":Þ\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‑/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":‑\\|\":\"Straight face\",\n",
    "    u\":\\|\":\"Straight face\",\n",
    "    u\":$\":\"Embarrassed or blushing\",\n",
    "    u\":‑x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‑#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‑&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\"O:‑\\)\":\"Angel, saint or innocent\",\n",
    "    u\"O:\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:‑3\":\"Angel, saint or innocent\",\n",
    "    u\"0:3\":\"Angel, saint or innocent\",\n",
    "    u\"0:‑\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:\\)\":\"Angel, saint or innocent\",\n",
    "    u\":‑b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n",
    "    u\">:‑\\)\":\"Evil or devilish\",\n",
    "    u\">:\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:‑\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:\\)\":\"Evil or devilish\",\n",
    "    u\"3:‑\\)\":\"Evil or devilish\",\n",
    "    u\"3:\\)\":\"Evil or devilish\",\n",
    "    u\">;\\)\":\"Evil or devilish\",\n",
    "    u\"\\|;‑\\)\":\"Cool\",\n",
    "    u\"\\|‑O\":\"Bored\",\n",
    "    u\":‑J\":\"Tongue-in-cheek\",\n",
    "    u\"#‑\\)\":\"Party all night\",\n",
    "    u\"%‑\\)\":\"Drunk or confused\",\n",
    "    u\"%\\)\":\"Drunk or confused\",\n",
    "    u\":-###..\":\"Being sick\",\n",
    "    u\":###..\":\"Being sick\",\n",
    "    u\"<:‑\\|\":\"Dump\",\n",
    "    u\"\\(>_<\\)\":\"Troubled\",\n",
    "    u\"\\(>_<\\)>\":\"Troubled\",\n",
    "    u\"\\(';'\\)\":\"Baby\",\n",
    "    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(~_~;\\) \\(・\\.・;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-\\)zzz\":\"Sleeping\",\n",
    "    u\"\\(\\^_-\\)\":\"Wink\",\n",
    "    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n",
    "    u\"\\(\\+o\\+\\)\":\"Confused\",\n",
    "    u\"\\(o\\|o\\)\":\"Ultraman\",\n",
    "    u\"\\^_\\^\":\"Joyful\",\n",
    "    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n",
    "    u\"\\(\\^O\\^\\)／\":\"Joyful\",\n",
    "    u\"\\(\\^o\\^\\)／\":\"Joyful\",\n",
    "    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"\\('_'\\)\":\"Sad or Crying\",\n",
    "    u\"\\(/_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;_;\":\"Sad of Crying\",\n",
    "    u\"\\(;_:\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;O;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(:_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(ToT\\)\":\"Sad or Crying\",\n",
    "    u\";_;\":\"Sad or Crying\",\n",
    "    u\";-;\":\"Sad or Crying\",\n",
    "    u\";n;\":\"Sad or Crying\",\n",
    "    u\";;\":\"Sad or Crying\",\n",
    "    u\"Q\\.Q\":\"Sad or Crying\",\n",
    "    u\"T\\.T\":\"Sad or Crying\",\n",
    "    u\"QQ\":\"Sad or Crying\",\n",
    "    u\"Q_Q\":\"Sad or Crying\",\n",
    "    u\"\\(-\\.-\\)\":\"Shame\",\n",
    "    u\"\\(-_-\\)\":\"Shame\",\n",
    "    u\"\\(一一\\)\":\"Shame\",\n",
    "    u\"\\(；一_一\\)\":\"Shame\",\n",
    "    u\"\\(=_=\\)\":\"Tired\",\n",
    "    u\"\\(=\\^\\·\\^=\\)\":\"cat\",\n",
    "    u\"\\(=\\^\\·\\·\\^=\\)\":\"cat\",\n",
    "    u\"=_\\^=\t\":\"cat\",\n",
    "    u\"\\(\\.\\.\\)\":\"Looking down\",\n",
    "    u\"\\(\\._\\.\\)\":\"Looking down\",\n",
    "    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n",
    "    u\"\\(\\・\\・?\":\"Confusion\",\n",
    "    u\"\\(?_?\\)\":\"Confusion\",\n",
    "    u\">\\^_\\^<\":\"Normal Laugh\",\n",
    "    u\"<\\^!\\^>\":\"Normal Laugh\",\n",
    "    u\"\\^/\\^\":\"Normal Laugh\",\n",
    "    u\"\\（\\*\\^_\\^\\*）\" :\"Normal Laugh\",\n",
    "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^—\\^\\）\":\"Normal Laugh\",\n",
    "    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n",
    "    u\"\\（\\^—\\^\\）\":\"Waving\",\n",
    "    u\"\\(;_;\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n",
    "    u\"\\(-_-\\)/~~~ \\($\\·\\·\\)/~~~\":\"Waving\",\n",
    "    u\"\\(T_T\\)/~~~\":\"Waving\",\n",
    "    u\"\\(ToT\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n",
    "    u\"\\(\\*_\\*\\)\":\"Amazed\",\n",
    "    u\"\\(\\*_\\*;\":\"Amazed\",\n",
    "    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n",
    "    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n",
    "    u'\\(-\"-\\)':\"Worried\",\n",
    "    u\"\\(ーー;\\)\":\"Worried\",\n",
    "    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n",
    "    u\"\\(\\＾ｖ\\＾\\)\":\"Happy\",\n",
    "    u\"\\(\\＾ｕ\\＾\\)\":\"Happy\",\n",
    "    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^O\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^o\\^\\)\":\"Happy\",\n",
    "    u\"\\)\\^o\\^\\(\":\"Happy\",\n",
    "    u\":O o_O\":\"Surprised\",\n",
    "    u\"o_0\":\"Surprised\",\n",
    "    u\"o\\.O\":\"Surpised\",\n",
    "    u\"\\(o\\.o\\)\":\"Surprised\",\n",
    "    u\"oO\":\"Surprised\",\n",
    "    u\"\\(\\*￣m￣\\)\":\"Dissatisfied\",\n",
    "    u\"\\(‘A`\\)\":\"Snubbed or Deflated\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0afe654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoticons(self_text):\n",
    "    emoticons_pattern = re.compile(u'(' + u'|'.join(emo for emo in EMOTICONS) + u')')\n",
    "    return emoticons_pattern.sub(r'', self_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ccd7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.apply(lambda x: remove_emoticons(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7447a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da12354",
   "metadata": {},
   "source": [
    "# Emojileri metne çevirme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31575a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yusuf\\AppData\\Local\\Temp\\ipykernel_15052\\2299328559.py:1: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45b1639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_to_words(self_text):\n",
    "    return demoji.replace_with_desc(self_text, sep=\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65103edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.apply(lambda x: emoji_to_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "863be7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6270c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticons_to_words(self_text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").replace(\":\",\"\").split()), self_text)\n",
    "    return self_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88fde2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.apply(lambda x: emoticons_to_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d95a450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e117f7",
   "metadata": {},
   "source": [
    "# Hashtag silme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f71e73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_mentions(self_text):\n",
    "    pattern = re.compile(r'(@\\S+|#\\S+)')\n",
    "    return pattern.sub('', self_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "662eeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri setinden hastagları silme\n",
    "df.self_text = df.self_text.apply(lambda x: remove_tags_mentions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2955c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistan-afghanis...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>that's like the most notable thing about the v...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>'you thinking what i'm thinking?\"\\n\\n\"aim for ...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistan-afghanis...   \n",
       "3    k9tjoep      1  that's like the most notable thing about the v...   \n",
       "4    k9tjicm      2  'you thinking what i'm thinking?\"\\n\\n\"aim for ...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6caa7",
   "metadata": {},
   "source": [
    "# Noktalama işaretleri harfler ve rakamlardan farklı karakterlerdir. Bunlar arasında [!\"#$%&'()*+,-./:;<=>?@\\^_`{|}~] bulunur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5aff3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATIONS = string.punctuation\n",
    "\n",
    "def remove_punctuation(self_text):\n",
    "        return self_text.translate(str.maketrans('', '', PUNCTUATIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3aeefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df[\"self_text\"].apply(lambda self_text: remove_punctuation(self_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e215d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel is like the most ethnically diverse cou...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>the only people starving them is hamas who kee...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>the casualty numbers for the pakistanafghanist...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>thats like the most notable thing about the vi...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>you thinking what im thinking\\n\\naim for the b...</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel is like the most ethnically diverse cou...   \n",
       "1    k9tjwfv      1  the only people starving them is hamas who kee...   \n",
       "2    k9tjpdl      1  the casualty numbers for the pakistanafghanist...   \n",
       "3    k9tjoep      1  thats like the most notable thing about the vi...   \n",
       "4    k9tjicm      2  you thinking what im thinking\\n\\naim for the b...   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84ba79",
   "metadata": {},
   "source": [
    "# Stopwords herhangi bir dilde yaygın olarak kullanılan kelimelerdir. Mesela İngilizce'de bu kelimeler 'the', 'a', 'an' ve çok daha fazlasıdır. Çoğu durumda yararlı değildirler ve kaldırılmaları gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06d28329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yusuf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9570b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(self_text):\n",
    "    return ' '.join([word for word in self_text.split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf883b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel like ethnically diverse country middle ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>people starving hamas keeps hoarding aid food ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>casualty numbers pakistanafghanistan conflict ...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>thats like notable thing video lmaoo nice one</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>thinking im thinking aim bushes</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel like ethnically diverse country middle ...   \n",
       "1    k9tjwfv      1  people starving hamas keeps hoarding aid food ...   \n",
       "2    k9tjpdl      1  casualty numbers pakistanafghanistan conflict ...   \n",
       "3    k9tjoep      1      thats like notable thing video lmaoo nice one   \n",
       "4    k9tjicm      2                    thinking im thinking aim bushes   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.self_text = df.self_text.apply(lambda self_text: remove_stopwords(self_text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2aed9",
   "metadata": {},
   "source": [
    "# fazla boşlukları silme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83ffd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespaces(self_text):\n",
    "    return \" \".join(self_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6d81db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.self_text = df.self_text.apply(lambda x: remove_whitespaces(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2080ece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9tk1p2</td>\n",
       "      <td>1</td>\n",
       "      <td>israel like ethnically diverse country middle ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:58:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k9tjwfv</td>\n",
       "      <td>1</td>\n",
       "      <td>people starving hamas keeps hoarding aid food ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-11-18 22:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k9tjpdl</td>\n",
       "      <td>1</td>\n",
       "      <td>casualty numbers pakistanafghanistan conflict ...</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>2023-11-18 22:55:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k9tjoep</td>\n",
       "      <td>1</td>\n",
       "      <td>thats like notable thing video lmaoo nice one</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:55:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k9tjicm</td>\n",
       "      <td>2</td>\n",
       "      <td>thinking im thinking aim bushes</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>2023-11-18 22:54:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  score                                          self_text  \\\n",
       "0    k9tk1p2      1  israel like ethnically diverse country middle ...   \n",
       "1    k9tjwfv      1  people starving hamas keeps hoarding aid food ...   \n",
       "2    k9tjpdl      1  casualty numbers pakistanafghanistan conflict ...   \n",
       "3    k9tjoep      1      thats like notable thing video lmaoo nice one   \n",
       "4    k9tjicm      2                    thinking im thinking aim bushes   \n",
       "\n",
       "            subreddit               created_time  \n",
       "0     IsraelPalestine  2023-11-18 22:58:37+00:00  \n",
       "1     IsraelPalestine  2023-11-18 22:57:30+00:00  \n",
       "2       CombatFootage  2023-11-18 22:55:57+00:00  \n",
       "3  NonCredibleDefense  2023-11-18 22:55:44+00:00  \n",
       "4  NonCredibleDefense  2023-11-18 22:54:26+00:00  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbce7f1",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "## Kök çıkarmada, kelimedeki ek karakterleri çıkararak kelimeyi temel veya kök şekline indirgemekteyiz.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "592fd457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(self_text):\n",
    "    return ' '.join([stemmer.stem(word) for word in self_text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fa8bf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self_text</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>israel like ethnically diverse country middle ...</td>\n",
       "      <td>israel like ethnic divers countri middl east talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people starving hamas keeps hoarding aid food ...</td>\n",
       "      <td>peopl starv hama keep hoard aid food shoot civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casualty numbers pakistanafghanistan conflict ...</td>\n",
       "      <td>casualti number pakistanafghanistan conflict a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thats like notable thing video lmaoo nice one</td>\n",
       "      <td>that like notabl thing video lmaoo nice one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thinking im thinking aim bushes</td>\n",
       "      <td>think im think aim bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           self_text  \\\n",
       "0  israel like ethnically diverse country middle ...   \n",
       "1  people starving hamas keeps hoarding aid food ...   \n",
       "2  casualty numbers pakistanafghanistan conflict ...   \n",
       "3      thats like notable thing video lmaoo nice one   \n",
       "4                    thinking im thinking aim bushes   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  israel like ethnic divers countri middl east talk  \n",
       "1  peopl starv hama keep hoard aid food shoot civ...  \n",
       "2  casualti number pakistanafghanistan conflict a...  \n",
       "3        that like notabl thing video lmaoo nice one  \n",
       "4                            think im think aim bush  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_stemmed'] = df.self_text.apply(lambda self_text: stem_words(self_text))\n",
    "df[['self_text', 'text_stemmed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a44e3",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "## Lemmatizasyon, kök çıkarma görevine benzer bir görevi yerine getirmeye çalışmaktadır. Lemmatizasyonlar kelimenin morfolojik analizini dikkate alır. Kelimeleri lemma adı verilen sözlük şekline indirgemeye çalışır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "030e9d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yusuf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "305dad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_lemmatize(self_text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in self_text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4dcbd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self_text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>israel like ethnically diverse country middle ...</td>\n",
       "      <td>israel like ethnic divers countri middl east talk</td>\n",
       "      <td>israel like ethnically diverse country middle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people starving hamas keeps hoarding aid food ...</td>\n",
       "      <td>peopl starv hama keep hoard aid food shoot civ...</td>\n",
       "      <td>people starving hamas keep hoarding aid food s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casualty numbers pakistanafghanistan conflict ...</td>\n",
       "      <td>casualti number pakistanafghanistan conflict a...</td>\n",
       "      <td>casualty number pakistanafghanistan conflict a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thats like notable thing video lmaoo nice one</td>\n",
       "      <td>that like notabl thing video lmaoo nice one</td>\n",
       "      <td>thats like notable thing video lmaoo nice one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thinking im thinking aim bushes</td>\n",
       "      <td>think im think aim bush</td>\n",
       "      <td>thinking im thinking aim bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           self_text  \\\n",
       "0  israel like ethnically diverse country middle ...   \n",
       "1  people starving hamas keeps hoarding aid food ...   \n",
       "2  casualty numbers pakistanafghanistan conflict ...   \n",
       "3      thats like notable thing video lmaoo nice one   \n",
       "4                    thinking im thinking aim bushes   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  israel like ethnic divers countri middl east talk   \n",
       "1  peopl starv hama keep hoard aid food shoot civ...   \n",
       "2  casualti number pakistanafghanistan conflict a...   \n",
       "3        that like notabl thing video lmaoo nice one   \n",
       "4                            think im think aim bush   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  israel like ethnically diverse country middle ...  \n",
       "1  people starving hamas keep hoarding aid food s...  \n",
       "2  casualty number pakistanafghanistan conflict a...  \n",
       "3      thats like notable thing video lmaoo nice one  \n",
       "4                      thinking im thinking aim bush  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lemmatized'] = df.self_text.apply(lambda x: text_lemmatize(x))\n",
    "df[['self_text', 'text_stemmed', 'text_lemmatized']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cac23c",
   "metadata": {},
   "source": [
    "# Yazım hatası düzeltme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "45cc6d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "475ee66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf8eb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(self_text):\n",
    "    correct_text = []\n",
    "    misspelled_words = spell.unknown(self_text.split())\n",
    "    for word in self_text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_word = spell.correction(word)\n",
    "            # Eğer kelime düzeltildiyse, düzeltilmiş halini ekler\n",
    "            if corrected_word is not None:\n",
    "                correct_text.append(corrected_word)\n",
    "            # Eğer kelime düzeltilmediyse, orijinal halini ekler\n",
    "            else:\n",
    "                correct_text.append(word)\n",
    "        else:\n",
    "            correct_text.append(word)\n",
    "    return \" \".join(correct_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72342887",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrected_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_lemmatized\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(correct_spelling)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[57], line 8\u001b[0m, in \u001b[0;36mcorrect_spelling\u001b[1;34m(self_text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m self_text\u001b[38;5;241m.\u001b[39msplit():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m misspelled_words:\n\u001b[1;32m----> 8\u001b[0m         corrected_word \u001b[38;5;241m=\u001b[39m spell\u001b[38;5;241m.\u001b[39mcorrection(word)\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Eğer kelime düzeltildiyse, düzeltilmiş halini ekler\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m corrected_word \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\spellchecker.py:158\u001b[0m, in \u001b[0;36mSpellChecker.correction\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The most probable correct spelling for the word\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    word (str): The word to correct\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    str: The most likely candidate or None if no correction is present\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m word \u001b[38;5;241m=\u001b[39m ensure_unicode(word)\n\u001b[1;32m--> 158\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates(word)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\spellchecker.py:185\u001b[0m, in \u001b[0;36mSpellChecker.candidates\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# if still not found, use the edit distance 1 to calc edit distance 2\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distance \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 185\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__edit_distance_alt(res)))\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tmp:\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tmp\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\spellchecker.py:252\u001b[0m, in \u001b[0;36mSpellChecker.__edit_distance_alt\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    250\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    251\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medit_distance_1(e1))]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\spellchecker.py:252\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    251\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medit_distance_1(e1))]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\spellchecker.py:197\u001b[0m, in \u001b[0;36mSpellChecker.known\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mknown\u001b[39m(\u001b[38;5;28mself\u001b[39m, words: typing\u001b[38;5;241m.\u001b[39mIterable[KeyT]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mSet[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The subset of `words` that appear in the dictionary of words\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        words (list): List of words to determine which are in the corpus\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        set: The set of those words from the input that are in the corpus\"\"\"\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m     tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    198\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words]\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word_frequency\u001b[38;5;241m.\u001b[39mdictionary \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)}\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\spellchecker.py:197\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mknown\u001b[39m(\u001b[38;5;28mself\u001b[39m, words: typing\u001b[38;5;241m.\u001b[39mIterable[KeyT]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mSet[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The subset of `words` that appear in the dictionary of words\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        words (list): List of words to determine which are in the corpus\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        set: The set of those words from the input that are in the corpus\"\"\"\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m     tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    198\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words]\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word_frequency\u001b[38;5;241m.\u001b[39mdictionary \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)}\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\spellchecker\\utils.py:66\u001b[0m, in \u001b[0;36mensure_unicode\u001b[1;34m(value, encoding)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function_wrapper\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decorator_wrapper\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_unicode\u001b[39m(value: KeyT, encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simplify checking if passed in data are bytes or a string and decode\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    bytes into unicode.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m        str: The encoded string\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['corrected_text'] = df['text_lemmatized'].apply(correct_spelling)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db738e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
